---
applyTo: '**'
---
# OCR Model Usage Guide - Language Agnostic

This document describes how to use the OCR models and decode text using the character dictionary, independent of any specific programming language.

## üìÅ Model Files Overview

The OCR system consists of three essential files:

| File | Purpose | Format |
|------|---------|--------|
| `onnx_models/det_model.onnx` | Text detection model | ONNX (4.7 MB) |
| `onnx_models/rec_model.onnx` | Text recognition model | ONNX (10.8 MB) |
| `ppocr_keys_v1.txt` | Character dictionary | Plain text (UTF-8) |

## üèóÔ∏è Model Architecture

### Detection Model (det_model.onnx)
- **Purpose**: Locates text regions in images
- **Input**: RGB image tensor
  - Shape: `(1, 3, 640, 640)`
  - Data type: Float32
  - Value range: [0.0, 1.0] (normalized)
  - Format: NCHW (Batch, Channels, Height, Width)
- **Output**: Probability heatmap
  - Shape: `(1, 1, 640, 640)`
  - Data type: Float32
  - Value range: [0.0, 1.0] (probability of text presence)

### Recognition Model (rec_model.onnx)
- **Purpose**: Recognizes text characters from detected regions
- **Input**: RGB image tensor
  - Shape: `(1, 3, 48, 320)`
  - Data type: Float32
  - Value range: [0.0, 1.0] (normalized)
  - Format: NCHW (Batch, Channels, Height, Width)
  - Height is fixed at 48 pixels
  - Width is fixed at 320 pixels
- **Output**: Character probability logits
  - Shape: `(1, 40, 6624)`
  - Data type: Float32
  - 40 time steps (sequence length)
  - 6624 classes (1 blank + 6623 characters)

## üìñ Dictionary File Format

### File: `ppocr_keys_v1.txt`

**Format Specification:**
- Encoding: UTF-8
- Line separator: LF (`\n`)
- Total lines: 6623
- Each line contains exactly one character
- No blank or empty lines
- Includes: Chinese characters (simplified & traditional), English letters, numbers, punctuation

**Character Mapping:**
```
Line 1  ‚Üí Index 1  ‚Üí Character: '
Line 2  ‚Üí Index 2  ‚Üí Character: Áñó
Line 3  ‚Üí Index 3  ‚Üí Character: Áªö
...
Line 6623 ‚Üí Index 6623 ‚Üí Character: (last character)
```

**Special Index:**
- Index 0 is reserved for `<blank>` (CTC blank token)
- Index 0 does NOT appear in the dictionary file

## üîÑ Processing Pipeline

### Step 1: Image Preprocessing (Recognition)

**Input Requirements:**
- Any image containing text
- Recommended: High contrast between text and background

**Preprocessing Steps:**

1. **Resize Image**
   - Target size: 320 √ó 48 pixels (width √ó height)
   - Aspect ratio is NOT preserved
   - Interpolation: Bilinear or similar

2. **Normalize Pixel Values**
   - Original range: [0, 255] (uint8)
   - Target range: [0.0, 1.0] (float32)
   - Formula: `normalized_value = pixel_value / 255.0`

3. **Color Space Conversion**
   - Convert: BGR ‚Üí RGB (if input is BGR)
   - OpenCV uses BGR by default
   - Most frameworks expect RGB

4. **Transpose to NCHW Format**
   - Original: (Height, Width, Channels) = (48, 320, 3)
   - Target: (Channels, Height, Width) = (3, 48, 320)
   - Permutation: (2, 0, 1) or equivalent

5. **Add Batch Dimension**
   - Original: (3, 48, 320)
   - Target: (1, 3, 48, 320)
   - Add dimension at position 0

**Pseudocode:**
```
function preprocess_image(image):
    # 1. Resize
    resized = resize(image, width=320, height=48)
    
    # 2. Normalize
    normalized = convert_to_float32(resized) / 255.0
    
    # 3. BGR to RGB (if needed)
    rgb = bgr_to_rgb(normalized)
    
    # 4. Transpose to CHW
    chw = transpose(rgb, axes=[2, 0, 1])
    
    # 5. Add batch dimension
    batch = expand_dims(chw, axis=0)
    
    return batch  # Shape: (1, 3, 48, 320)
```

### Step 2: Model Inference

**Execute Model:**
```
input_tensor = preprocess_image(image)
output_tensor = run_inference(rec_model, input_tensor)
```

**Output Format:**
- Shape: `(1, 40, 6625)`
- Batch size: 1
- Sequence length: 40 (time steps)
- Number of classes: 6625
- Each value represents the unnormalized log probability (logit) for that class at that time step

### Step 3: Decode Predictions

**Extract Class Indices:**
```
For each time step t from 0 to 39:
    class_index[t] = argmax(output_tensor[0, t, :])
```

Result: Array of 40 integers, each in range [0, 6623]

**Example Output:**
```
[0, 0, 1234, 1234, 0, 2345, 0, 3456, 3456, 3456, 0, 0, ...]
```

### Step 4: CTC Decoding Algorithm

**CTC (Connectionist Temporal Classification) Decoding:**

CTC decoding removes duplicate consecutive predictions and blank tokens to produce the final text.

**Algorithm:**
```
function ctc_decode(class_indices, character_dictionary):
    decoded_characters = []
    previous_index = -1  # Initialize with invalid index
    
    for current_index in class_indices:
        # Rule 1: Skip blank tokens (index 0)
        if current_index == 0:
            previous_index = current_index
            continue
        
        # Rule 2: Skip consecutive duplicates
        if current_index == previous_index:
            previous_index = current_index
            continue
        
        # Rule 3: Map valid indices to characters
        if current_index >= 1 and current_index <= len(character_dictionary):
            character = character_dictionary[current_index]
            decoded_characters.append(character)
        
        previous_index = current_index
    
    # Join characters to form final text
    result = join(decoded_characters)
    return result
```

**Key CTC Rules:**
1. **Blank Token (0)**: Always ignored in final output
2. **Consecutive Duplicates**: Only first occurrence is kept
3. **Valid Indices**: Must be in range [1, 6623]

### Step 5: Character Mapping

**Dictionary Lookup:**

The character dictionary is loaded as a 1-indexed array:

```
dictionary[0] = "<blank>"  # Not in file, added programmatically
dictionary[1] = first line of ppocr_keys_v1.txt
dictionary[2] = second line of ppocr_keys_v1.txt
...
dictionary[6623] = last line of ppocr_keys_v1.txt
```

**Mapping Process:**
```
For each predicted_index in decoded_indices:
    if predicted_index == 0:
        # Skip blank
        continue
    else if predicted_index >= 1 and predicted_index <= 6623:
        character = dictionary[predicted_index]
        append character to result
    else:
        # Handle out-of-range error
        append "[UNKNOWN]" to result
```

## üìä Complete Example with Data

### Input Image
- File: `test_image.png`
- Content: Chinese text "Âà´‰∫∫ÈÉΩÂú®ÁñØÁãÇÂõ§ÁùÄÁâ©ËµÑ"
- Size: 1000 √ó 200 pixels

### Preprocessing Output
```
Shape: (1, 3, 48, 320)
Data type: float32
Value range: [0.0, 1.0]
```

### Model Output (Simplified)
```
Shape: (1, 40, 6624)
Logits at time step 0: [0.1, -2.3, 5.6, ..., -1.2]  (6624 values)
Logits at time step 1: [0.3, -1.8, 4.2, ..., -0.9]  (6624 values)
...
```

### ArgMax Results
```
Time steps:  [0,   1,   2,   3,   4,   5,   6,   7,   8,   9,   10,  ...]
Indices:     [0,   617, 617, 0,   198, 198, 198, 0,   793, 793, 0,   ...]
```

### After CTC Decoding
```
Original:    [0,   617, 617, 0,   198, 198, 198, 0,   793, 793, 0,   ...]
After CTC:   [617, 198, 793, ...]
             (removed blanks and consecutive duplicates)
```

### Character Mapping
```
Index 617  ‚Üí Dictionary line 617  ‚Üí Character: "Âà´"
Index 198  ‚Üí Dictionary line 198  ‚Üí Character: "‰∫∫"
Index 793  ‚Üí Dictionary line 793  ‚Üí Character: "ÈÉΩ"
Index 106  ‚Üí Dictionary line 106  ‚Üí Character: "Âú®"
Index 61   ‚Üí Dictionary line 61   ‚Üí Character: "ÁñØ"
Index 131  ‚Üí Dictionary line 131  ‚Üí Character: "ÁãÇ"
Index 51   ‚Üí Dictionary line 51   ‚Üí Character: "Âõ§"
Index 808  ‚Üí Dictionary line 808  ‚Üí Character: "ÁùÄ"
Index 1449 ‚Üí Dictionary line 1449 ‚Üí Character: "Áâ©"
Index 51   ‚Üí Dictionary line 51   ‚Üí Character: "ËµÑ"
```

### Final Output
```
"Âà´‰∫∫ÈÉΩÂú®ÁñØÁãÇÂõ§ÁùÄÁâ©ËµÑ"
```

## üîß Implementation Checklist

When implementing this OCR system in any programming language:

- [ ] Load ONNX model using compatible runtime (ONNX Runtime, TensorRT, etc.)
- [ ] Load dictionary file with UTF-8 encoding
- [ ] Parse dictionary line by line (6623 lines)
- [ ] Add `<blank>` token at index 0
- [ ] Implement image preprocessing:
  - [ ] Resize to 320√ó48
  - [ ] Normalize to [0.0, 1.0]
  - [ ] Convert BGR to RGB (if needed)
  - [ ] Transpose to NCHW format
  - [ ] Add batch dimension
- [ ] Run model inference with input shape (1, 3, 48, 320)
- [ ] Extract output with shape (1, 40, 6624)
- [ ] Apply argmax along class dimension (axis=2)
- [ ] Implement CTC decoding:
  - [ ] Remove blank tokens (index 0)
  - [ ] Remove consecutive duplicates
- [ ] Map indices to characters using dictionary
- [ ] Join characters to form final text string

## ‚ö†Ô∏è Important Notes

1. **Index Offset**: Dictionary file is 1-indexed (first line = index 1), with index 0 reserved for blank

2. **UTF-8 Encoding**: Always use UTF-8 when reading the dictionary file to properly handle Chinese characters

3. **Model Input**: Height MUST be 48 pixels, width MUST be 320 pixels (fixed dimensions)

4. **CTC Blank**: Index 0 is the CTC blank token and should never appear in final output

5. **Consecutive Duplicates**: CTC decoding removes consecutive identical predictions, not all duplicates

6. **Performance**: Expected accuracy is 90%+ on clear, high-contrast Chinese text images

7. **Model Format**: ONNX models are platform-independent and can be used with various frameworks

## üéØ Summary

The OCR pipeline consists of:
1. **Preprocess** image to (1, 3, 48, 320) tensor
2. **Inference** recognition model to get (1, 40, 6624) logits
3. **ArgMax** to get class indices for 40 time steps
4. **CTC Decode** to remove blanks and duplicates
5. **Map** indices to characters using dictionary
6. **Join** characters to form final text

This process is independent of programming language and relies only on:
- Standard ONNX model inference
- Basic tensor operations (resize, normalize, transpose, argmax)
- UTF-8 text file reading
- String concatenation

---

**Version**: 1.0  
**Model**: PaddleOCR v1  
**Dictionary**: ppocr_keys_v1.txt (6623 characters)  
**Last Updated**: 2025-11-18
